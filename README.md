# gradient_descent_ridge_regression
Gradient Descent Techniques for Rigde Regression 

## Platform
Google Collab

## Language
Python

## Libraries
Sklearn, Pandas, Numpy

## Description / Goals 
Our goal is to implement the gradient descent, stochastic gradient descent and mini-batch gradient descent techiniques for ridge regression and apply them on the California Housing Dataset.
1. We present the best parametres, after experementation, for each technique in order to optimize our results.
2. We compare the techniques based on the $R^2$ metric, which represents the proportion of the variance in the dependent variable that is predictable from the independent variable(s).
3. We plot the Cost - Mean Square Error diagram for each experiment to observe the convergence and check for cases of overfitting / underfitting.

## Tips
Add the `HousingData.csv` dataset in your `gdrive/My Drive/Colab Notebooks/` path to execute correctly

## Author
Vassilis Panagakis

## Date
October 2020
